Sundry observations about concurrency abstractions.

Probably the Multicore system could build on a task channel
abstraction: right now it has a custom channel of fixed capacity and
can't handle a larger number of work items than that.  As a result it
overallocates memory for itself.  That can be fixed, even within the
current system, by allocating smaller metadata chunks and just
distributing more chunks on demand.

A task channel (a la GCD) would take work items, which are just
bundles of function ID + parameters, and queue them up for execution
on some suitable worker.  Part of the problem with that is that not
all workers are suitable (because they haven't loaded the program).
So there is probably some notion of a pool of workers tied to a queue,
and tasks on that queue.

-------------------- 

For handwritten-JS the main use case is certainly as a computation
engine to offload the main thread and also to exploit multicore.

Usability of the low-level features can be improved by:

- higher-level abstractions (data-parallel and task-parallel) that are
  largely deadlock-free because they use locks in extremely structured
  ways or not at all; of course it's never quite that simple but
  it indisputably helps.

- code generation from a higher-level language, to take some of the
  drudgery out of it, though it more or less amounts to the same thing
  as a high-level language

- low-level toolable abstractions (actual locks with hooks into the
  tools) /or/ some form of instrumentation that allows tools to help

--------------------

Consider futexWait.  What does "deadlock" mean?  It means that there
is a clique of workers (incl the main thread) that are waiting on each
other.  Even including the main thread is a problem because any event
can make it runnable.  And if the main thread is runnable it can
perform a futexWake to wake any waiting thread.  So a deadlock is
really something else (or there are no deadlocks, only livelocks).

--------------------

A task queue is a data structure where tasks can be inserted by both
master and workers and where the master runs some code to distribute
tasks to workers.

GCD can wait on task groups, which are always async (and thus it waits
for completion of all the tasks in the group), or it can execute tasks
synchronously.

--------------------

A simple generalization allows literal code to be used as the argument
for Multicore.build:

// source must evaluate (on the worker) to a function value, and will
// be invoked directly.

Multicore.buildFn(k, source, ...) 

// ditto for broadcast:

Multicore.broadcastFn(k, source, ...)

These could use a custom protocol or could just broadcast the code
with eval under a hidden name before the build.  There could be
caching to avoid rebroadcast, though only if the source is literally a
function expression, not something that computes a function value in
some complicated way that may contain local state.  For example,
consider this:

Multicore.buildFn(k, "(function () { var sum=0; return function (mem, lo, hi) { for ( var i=lo ; i < hi ; i++ ) { sum += mem[i]; mem[i] = sum; } } })()", ...);

Indeed should the expression be reevaluated for every slice?  That
does not seem reasonable.

--------------------

It would be nice to be able to use data: URLs as arguments to new
Worker, and that works for simple ones but not for one containing
importScripts.  It appears to be a cross-origin problem.  See
http://www.html5rocks.com/en/tutorials/workers/basics/ and search for
"Blob URLs", which are similar to data urls and have similar issues.

// Create an empty worker.  Effectively this should evaluate to
// "data:application/javascript,importScripts('DIR/asymmetric-barrier.js','DIR/parinvoke-worker.js')",

This appears to be the way to do it:

var me = String(document.location);
var blob = new Blob(["importScripts('" + me.substring(0,me.lastIndexOf("/")+1) + "dataurl-extern.js')"]);
var blobUrl = URL.createObjectURL(blob);
Multicore.init(1, blobUrl, function () { URL.releaseObjectURL(blobUrl); ... });

