Sundry observations about concurrency abstractions.

Probably the Multicore system could build on a task channel
abstraction: right now it has a custom channel of fixed capacity and
can't handle a larger number of work items than that.  As a result it
overallocates memory for itself.  That can be fixed, even within the
current system, by allocating smaller metadata chunks and just
distributing more chunks on demand.

A task channel (a la GCD) would take work items, which are just
bundles of function ID + parameters, and queue them up for execution
on some suitable worker.  Part of the problem with that is that not
all workers are suitable (because they haven't loaded the program).
So there is probably some notion of a pool of workers tied to a queue,
and tasks on that queue.

-------------------- 

For handwritten-JS the main use case is certainly as a computation
engine to offload the main thread and also to exploit multicore.

Usability of the low-level features can be improved by:

- higher-level abstractions (data-parallel and task-parallel) that are
  largely deadlock-free because they use locks in extremely structured
  ways or not at all; of course it's never quite that simple but
  it indisputably helps.

- code generation from a higher-level language, to take some of the
  drudgery out of it, though it more or less amounts to the same thing
  as a high-level language

- low-level toolable abstractions (actual locks with hooks into the
  tools) /or/ some form of instrumentation that allows tools to help

--------------------

Consider futexWait.  What does "deadlock" mean?  It means that there
is a clique of workers (incl the main thread) that are waiting on each
other.  Even including the main thread is a problem because any event
can make it runnable.  And if the main thread is runnable it can
perform a futexWake to wake any waiting thread.  So a deadlock is
really something else (or there are no deadlocks, only livelocks).

--------------------

A task queue is a data structure where tasks can be inserted by both
master and workers and where the master runs some code to distribute
tasks to workers.

GCD can wait on task groups, which are always async (and thus it waits
for completion of all the tasks in the group), or it can execute tasks
synchronously.

--------------------

A simple generalization allows literal code to be used as the argument
for Multicore.build:

// source must evaluate (on the worker) to a function value, and will
// be invoked directly.

Multicore.buildFn(k, source, ...) 

// ditto for broadcast:

Multicore.broadcastFn(k, source, ...)

These could use a custom protocol or could just broadcast the code
with eval under a hidden name before the build.  There could be
caching to avoid rebroadcast, though only if the source is literally a
function expression, not something that computes a function value in
some complicated way that may contain local state.  For example,
consider this:

Multicore.buildFn(k, "(function () { var sum=0; return function (mem, lo, hi) { for ( var i=lo ; i < hi ; i++ ) { sum += mem[i]; mem[i] = sum; } } })()", ...);

Indeed should the expression be reevaluated for every slice?  That
does not seem reasonable.

--------------------

It would be nice to be able to use data: URLs as arguments to new
Worker, and that works for simple ones but not for one containing
importScripts.  It appears to be a cross-origin problem.  See
http://www.html5rocks.com/en/tutorials/workers/basics/ and search for
"Blob URLs", which are similar to data urls and have similar issues.

// Create an empty worker.  Effectively this should evaluate to
// "data:application/javascript,importScripts('DIR/asymmetric-barrier.js','DIR/parinvoke-worker.js')",

This appears to be the way to do it:

var me = String(document.location);
var blob = new Blob(["importScripts('" + me.substring(0,me.lastIndexOf("/")+1) + "dataurl-extern.js')"]);
var blobUrl = URL.createObjectURL(blob);
Multicore.init(1, blobUrl, function () { URL.releaseObjectURL(blobUrl); ... });

----------------------------------------

What's the meaning of nested Multicore.build calls?

A nested build is really an insertion into the beginning of the task
queue of a new set of work items, along with a barrier.  Or perhaps
the better conception is that it is a new, higher priority task queue,
with an implicit barrier.

That is, when a worker is looking for work it will take the first
available task from the highest priority task queue, and when that
queue is drained it will enter a barrier (and all will participate in
that barrier).

However this means the worker needs to participate in some kind of
callback scheme (for the barrier), it certainly can't block directly.
But here's what it is:

Multicore.build = function (cb, fn, mem, ix, ...args) {
  var q = create_queue(ix);
  push_queue(q);		// Racy: other workers may enter a different barrier... so there can be only one barrier object
  while (any_work_in_any_queue_not_at_lowest_pri) {
     while (t = get_hipri_task())
       t();
    barrier();
  }
}

It's possible that the priority levels are more structured and
correspond directly to the nesting level of build.  But I'm not sure
how we handle barriers in that case.

Also the nested builds may have created shared memory objects that
need to be distributed to all workers, which means all workers must
exit to the event loop in any case.

----------------------------------------

Two-pass separable convolution:

In this case one would process along rows in the first pass and along
columns in the second pass, so one might want to stripe the grid first
along one dimension and then along the other.  The hints to Multicore
may not handle that because it requires that if a dimension is split
then all the dimensions to its left are also split.  That's probably
an artificial limitation.  We could clearly split along one, the
other, or both, and we should take the presence of a hint in one
direction to mean that the absence of a hint in the other direction
means "don't split".
